{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Suppress warnings\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "RMRL67DOhNkN"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yfcj0HtTpZ7P"
      },
      "outputs": [],
      "source": [
        "# Check torchtext version\n",
        "\n",
        "import torchtext\n",
        "print(torchtext.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.datasets import multi30k,Multi30k\n",
        "from typing import Iterable,List\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torchdata.datapipes.iter import IterableWrapper,Mapper\n",
        "import torchtext\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import numpy as np\n",
        "import random"
      ],
      "metadata": {
        "id": "_5-GzeqNpsl_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create custom dataset and dataloader\n",
        "\n",
        "sentences = [\n",
        "    \"If you want to know what a man's like, take a good look at how he treats his inferiors, not his equals.\",\n",
        "    \"Fame's a fickle friend, Harry.\",\n",
        "    \"It is our choices, Harry, that show what we truly are, far more than our abilities.\",\n",
        "    \"Soon we must all face the choice between what is right and what is easy.\",\n",
        "    \"Youth can not know how age thinks and feels. But old men are guilty if they forget what it was to be young.\",\n",
        "    \"You are awesome!\"\n",
        "]\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self,sentences):\n",
        "    self.sentences = sentences\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.sentences)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    return self.sentences[idx]\n",
        "\n",
        "custom_dataset = CustomDataset(sentences)\n",
        "\n",
        "batch_size = 2\n",
        "\n",
        "dataloader = DataLoader(custom_dataset,batch_size=batch_size,shuffle=True)\n",
        "\n",
        "for batch in dataloader:\n",
        "  print(batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KTvoaA9Cx_9",
        "outputId": "d5e9379d-8b0e-4f43-e9e1-eb4f95d9843a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"Fame's a fickle friend, Harry.\", 'Soon we must all face the choice between what is right and what is easy.']\n",
            "[\"If you want to know what a man's like, take a good look at how he treats his inferiors, not his equals.\", 'Youth can not know how age thinks and feels. But old men are guilty if they forget what it was to be young.']\n",
            "['You are awesome!', 'It is our choices, Harry, that show what we truly are, far more than our abilities.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Different custom dataset and dataloader\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self,sentences,tokenizer,vocab):\n",
        "    self.sentences = sentences\n",
        "    self.tokenizer = tokenizer\n",
        "    self.vocab = vocab\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.sentences)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    tokens = self.tokenizer(self.sentences[idx])\n",
        "    tensor_indices = [self.vocab[token] for token in tokens]\n",
        "    return torch.tensor(tensor_indices)\n",
        "\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "vocab = build_vocab_from_iterator(map(tokenizer,sentences))\n",
        "\n",
        "custom_dataset = CustomDataset(sentences,tokenizer,vocab)\n",
        "\n",
        "print('Custom Dataset Length:', len(custom_dataset))\n",
        "print('Sample Items:')\n",
        "for i in range(6):\n",
        "  sample_item = custom_dataset[i]\n",
        "  print(f'Item {i + 1}: {sample_item}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rZ5xzqYJHrU",
        "outputId": "2f805086-296a-435d-e202-335edfaaa2ac"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom Dataset Length: 6\n",
            "Sample Items:\n",
            "Item 1: tensor([11, 19, 63, 17, 13,  2,  3, 47,  6, 16, 45,  0, 55,  3, 41, 46, 24, 10,\n",
            "        43, 61,  9, 44,  0, 14,  9, 33,  1])\n",
            "Item 2: tensor([35,  6, 16,  3, 38, 40,  0,  8,  1])\n",
            "Item 3: tensor([12,  5, 15, 31,  0,  8,  0, 57, 53,  2, 18, 62,  4,  0, 36, 49, 56, 15,\n",
            "        21,  1])\n",
            "Item 4: tensor([54, 18, 50, 23, 34, 58, 30, 27,  2,  5, 52,  7,  2,  5, 32,  1])\n",
            "Item 5: tensor([66, 29, 14, 13, 10, 22, 60,  7, 37,  1, 28, 51, 48,  4, 42, 11, 59, 39,\n",
            "         2, 12, 64, 17, 26, 65,  1])\n",
            "Item 6: tensor([19,  4, 25, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom collate function\n",
        "\n",
        "def collate_fn(batch):\n",
        "  padded_batch = pad_sequence(batch,batch_first=True,padding_value=0)\n",
        "  return padded_batch\n",
        "\n",
        "vocab.insert_token(\"<pad>\", 0)"
      ],
      "metadata": {
        "id": "Eey-ZQTIZBZe"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataloader with custom collate function\n",
        "\n",
        "dataloader = DataLoader(custom_dataset,batch_size=batch_size,collate_fn=collate_fn)\n",
        "\n",
        "for batch in dataloader:\n",
        "    for row in batch:\n",
        "        words = [vocab.get_itos()[idx] for idx in row]\n",
        "    print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xa54zD6YkZds",
        "outputId": "91ab0495-4c9a-4116-a6dc-554b073d23b9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fame', \"'\", 's', 'a', 'fickle', 'friend', ',', 'harry', '.', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "['soon', 'we', 'must', 'all', 'face', 'the', 'choice', 'between', 'what', 'is', 'right', 'and', 'what', 'is', 'easy', '.', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "['you', 'are', 'awesome', '!', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# collate function with batch_first=False\n",
        "\n",
        "def collate_fn_bfFalse(batch):\n",
        "  padded_batch = pad_sequence(batch,padding_value=0)\n",
        "  return padded_batch"
      ],
      "metadata": {
        "id": "bKyqeEPFpE73"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataloader with custom collate function\n",
        "\n",
        "dataloader_bfFalse = DataLoader(custom_dataset,batch_size=batch_size,collate_fn=collate_fn_bfFalse)\n",
        "\n",
        "for seq in dataloader_bfFalse:\n",
        "  for row in seq:\n",
        "    #print(row)\n",
        "    words = [vocab.get_itos()[idx] for idx in row]\n",
        "    print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5uNaX2bqZD_",
        "outputId": "b83e47eb-83a4-4333-e7f3-31fae935eb3a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['if', 'fame']\n",
            "['you', \"'\"]\n",
            "['want', 's']\n",
            "['to', 'a']\n",
            "['know', 'fickle']\n",
            "['what', 'friend']\n",
            "['a', ',']\n",
            "['man', 'harry']\n",
            "[\"'\", '.']\n",
            "['s', '<pad>']\n",
            "['like', '<pad>']\n",
            "[',', '<pad>']\n",
            "['take', '<pad>']\n",
            "['a', '<pad>']\n",
            "['good', '<pad>']\n",
            "['look', '<pad>']\n",
            "['at', '<pad>']\n",
            "['how', '<pad>']\n",
            "['he', '<pad>']\n",
            "['treats', '<pad>']\n",
            "['his', '<pad>']\n",
            "['inferiors', '<pad>']\n",
            "[',', '<pad>']\n",
            "['not', '<pad>']\n",
            "['his', '<pad>']\n",
            "['equals', '<pad>']\n",
            "['.', '<pad>']\n",
            "['it', 'soon']\n",
            "['is', 'we']\n",
            "['our', 'must']\n",
            "['choices', 'all']\n",
            "[',', 'face']\n",
            "['harry', 'the']\n",
            "[',', 'choice']\n",
            "['that', 'between']\n",
            "['show', 'what']\n",
            "['what', 'is']\n",
            "['we', 'right']\n",
            "['truly', 'and']\n",
            "['are', 'what']\n",
            "[',', 'is']\n",
            "['far', 'easy']\n",
            "['more', '.']\n",
            "['than', '<pad>']\n",
            "['our', '<pad>']\n",
            "['abilities', '<pad>']\n",
            "['.', '<pad>']\n",
            "['youth', 'you']\n",
            "['can', 'are']\n",
            "['not', 'awesome']\n",
            "['know', '!']\n",
            "['how', '<pad>']\n",
            "['age', '<pad>']\n",
            "['thinks', '<pad>']\n",
            "['and', '<pad>']\n",
            "['feels', '<pad>']\n",
            "['.', '<pad>']\n",
            "['but', '<pad>']\n",
            "['old', '<pad>']\n",
            "['men', '<pad>']\n",
            "['are', '<pad>']\n",
            "['guilty', '<pad>']\n",
            "['if', '<pad>']\n",
            "['they', '<pad>']\n",
            "['forget', '<pad>']\n",
            "['what', '<pad>']\n",
            "['it', '<pad>']\n",
            "['was', '<pad>']\n",
            "['to', '<pad>']\n",
            "['be', '<pad>']\n",
            "['young', '<pad>']\n",
            "['.', '<pad>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check batches\n",
        "\n",
        "for batch in dataloader:\n",
        "  print(batch)\n",
        "  print('Length of sequences in the batch:',batch.shape[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FD7gEbORsMoi",
        "outputId": "64d89c73-fdee-4541-abd8-ceee965e9288"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[12, 20, 64, 18, 14,  3,  4, 48,  7, 17, 46,  1, 56,  4, 42, 47, 25, 11,\n",
            "         44, 62, 10, 45,  1, 15, 10, 34,  2],\n",
            "        [36,  7, 17,  4, 39, 41,  1,  9,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0]])\n",
            "Length of sequences in the batch: 27\n",
            "tensor([[13,  6, 16, 32,  1,  9,  1, 58, 54,  3, 19, 63,  5,  1, 37, 50, 57, 16,\n",
            "         22,  2],\n",
            "        [55, 19, 51, 24, 35, 59, 31, 28,  3,  6, 53,  8,  3,  6, 33,  2,  0,  0,\n",
            "          0,  0]])\n",
            "Length of sequences in the batch: 20\n",
            "tensor([[67, 30, 15, 14, 11, 23, 61,  8, 38,  2, 29, 52, 49,  5, 43, 12, 60, 40,\n",
            "          3, 13, 65, 18, 27, 66,  2],\n",
            "        [20,  5, 26, 21,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0]])\n",
            "Length of sequences in the batch: 25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# different custom dataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self,sentences):\n",
        "    self.sentences = sentences\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.sentences)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    return self.sentences[idx]"
      ],
      "metadata": {
        "id": "8HBQDAJ7tFF9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_dataset = CustomDataset(sentences)"
      ],
      "metadata": {
        "id": "kl9VUHyfuIbc"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YhB6SlCcuO6c",
        "outputId": "a19ffc36-8b34-4ed4-dd2b-66285ae0687f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"If you want to know what a man's like, take a good look at how he treats his inferiors, not his equals.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# different collate function\n",
        "\n",
        "def collate_fn(batch):\n",
        "  tensor_batch = []\n",
        "  for sample in batch:\n",
        "    tokens = tokenizer(sample)\n",
        "    tensor_batch.append(torch.tensor([vocab[token] for token in tokens]))\n",
        "\n",
        "  padded_batch = pad_sequence(tensor_batch,batch_first=True,padding_value=0)\n",
        "\n",
        "  return padded_batch"
      ],
      "metadata": {
        "id": "-hp4qyicuUQR"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(\n",
        "    dataset=custom_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn\n",
        ")"
      ],
      "metadata": {
        "id": "j1tIXlFSv7oP"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in dataloader:\n",
        "  print(batch)\n",
        "  print('shape of sample:', batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMTfFOtIwRiI",
        "outputId": "60a4cd59-400e-43e6-f4e3-6f76f28d3273"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13,  6, 16, 32,  1,  9,  1, 58, 54,  3, 19, 63,  5,  1, 37, 50, 57, 16,\n",
            "         22,  2],\n",
            "        [20,  5, 26, 21,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0]])\n",
            "shape of sample: torch.Size([2, 20])\n",
            "tensor([[67, 30, 15, 14, 11, 23, 61,  8, 38,  2, 29, 52, 49,  5, 43, 12, 60, 40,\n",
            "          3, 13, 65, 18, 27, 66,  2],\n",
            "        [36,  7, 17,  4, 39, 41,  1,  9,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0]])\n",
            "shape of sample: torch.Size([2, 25])\n",
            "tensor([[55, 19, 51, 24, 35, 59, 31, 28,  3,  6, 53,  8,  3,  6, 33,  2,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "        [12, 20, 64, 18, 14,  3,  4, 48,  7, 17, 46,  1, 56,  4, 42, 47, 25, 11,\n",
            "         44, 62, 10, 45,  1, 15, 10, 34,  2]])\n",
            "shape of sample: torch.Size([2, 27])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# french sentences\n",
        "\n",
        "corpus = [\n",
        "    \"Ceci est une phrase.\",\n",
        "    \"C'est un autre exemple de phrase.\",\n",
        "    \"Voici une troisième phrase.\",\n",
        "    \"Il fait beau aujourd'hui.\",\n",
        "    \"J'aime beaucoup la cuisine française.\",\n",
        "    \"Quel est ton plat préféré ?\",\n",
        "    \"Je t'adore.\",\n",
        "    \"Bon appétit !\",\n",
        "    \"Je suis en train d'apprendre le français.\",\n",
        "    \"Nous devons partir tôt demain matin.\",\n",
        "    \"Je suis heureux.\",\n",
        "    \"Le film était vraiment captivant !\",\n",
        "    \"Je suis là.\",\n",
        "    \"Je ne sais pas.\",\n",
        "    \"Je suis fatigué après une longue journée de travail.\",\n",
        "    \"Est-ce que tu as des projets pour le week-end ?\",\n",
        "    \"Je vais chez le médecin cet après-midi.\",\n",
        "    \"La musique adoucit les mœurs.\",\n",
        "    \"Je dois acheter du pain et du lait.\",\n",
        "    \"Il y a beaucoup de monde dans cette ville.\",\n",
        "    \"Merci beaucoup !\",\n",
        "    \"Au revoir !\",\n",
        "    \"Je suis ravi de vous rencontrer enfin !\",\n",
        "    \"Les vacances sont toujours trop courtes.\",\n",
        "    \"Je suis en retard.\",\n",
        "    \"Félicitations pour ton nouveau travail !\",\n",
        "    \"Je suis désolé, je ne peux pas venir à la réunion.\",\n",
        "    \"À quelle heure est le prochain train ?\",\n",
        "    \"Bonjour !\",\n",
        "    \"C'est génial !\"\n",
        "]"
      ],
      "metadata": {
        "id": "8OwvsniZwhKz"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# another custom collate function\n",
        "\n",
        "def collate_fn_fr(batch):\n",
        "  tensor_batch = []\n",
        "  for sample in batch:\n",
        "    tokens = tokenizer(sample)\n",
        "    tensor_batch.append(torch.tensor([vocab[token] for token in tokens]))\n",
        "\n",
        "  padded_batch = pad_sequence(tensor_batch,batch_first=True)\n",
        "  return padded_batch\n",
        "\n",
        "tokenizer = get_tokenizer('spacy',language='fr_core_news_sm')\n",
        "\n",
        "vocab = build_vocab_from_iterator(map(tokenizer,corpus))\n",
        "\n",
        "sorted_data = sorted(corpus, key=lambda x: len(tokenizer(x)))\n",
        "\n",
        "dataloader = DataLoader(sorted_data,batch_size=4,shuffle=False,collate_fn=collate_fn_fr)"
      ],
      "metadata": {
        "id": "E9pvtaTgzgCm"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in dataloader:\n",
        "  print(batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4JuliDh6kLL",
        "outputId": "ac60bfa1-58c0-4474-f30e-e9016f599728"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 27,   2,   0],\n",
            "        [ 26,  45,   2],\n",
            "        [ 35,   8,   2],\n",
            "        [ 25, 101,   2]])\n",
            "tensor([[  1, 105,  41,   0],\n",
            "        [  1,   3,  76,   0],\n",
            "        [  1,   3,  82,   0],\n",
            "        [ 11,   4,  74,   2]])\n",
            "tensor([[ 28,   4,  10,   9,   0],\n",
            "        [ 38,  10, 107,   9,   0],\n",
            "        [ 12,  69,  51,  49,   0],\n",
            "        [  1,  16, 103,  17,   0]])\n",
            "tensor([[  1,   3,  14, 100,   0,   0],\n",
            "        [ 37,   4,  19,  92,  95,   7],\n",
            "        [ 33,  71, 122, 117,  52,   2],\n",
            "        [ 32,  85,  42,  80,  87,   0]])\n",
            "tensor([[ 30,  18,  19,  88,  21,   2,   0],\n",
            "        [ 31,  43,   8,  15,  57,  73,   0],\n",
            "        [ 36,  62,  90, 110,  60,  83,   0],\n",
            "        [ 34, 112, 104, 106, 108,  56,   0]])\n",
            "tensor([[ 11,   4, 111,  50,  68,   5,   9,   0],\n",
            "        [  1, 113,  55,   6,  86,  53,  47,   0],\n",
            "        [  1,   3,  98,   5, 116,  99,  66,   2],\n",
            "        [120,  97,  75,   4,   6,  93,  20,   7]])\n",
            "tensor([[  1,   3,  14,  20,  58,  44,   6,  72,   0,   0],\n",
            "        [  1,  63,  40,  13,  89,  67,  13,  79,   0,   0],\n",
            "        [  1,   3,  70,  46,  10,  81,  78,   5,  21,   0],\n",
            "        [ 12, 119,  39,   8,   5,  84,  59,  54, 115,   0]])\n",
            "tensor([[ 29,  24,  96, 109,  48,  61,  94,  18,   6, 118,  23,  65,   7],\n",
            "        [  1,   3,  64,  22,  77,  16,  91,  17, 114, 121,  15, 102,   0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multi30k.URL[\"train\"] = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0205EN-SkillsNetwork/training.tar.gz\"\n",
        "multi30k.URL[\"valid\"] = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0205EN-SkillsNetwork/validation.tar.gz\""
      ],
      "metadata": {
        "id": "njgXnDkH6rbd"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define source language and target language\n",
        "\n",
        "SRC_LANGUAGE = 'de'\n",
        "TGT_LANGUAGE = 'en'"
      ],
      "metadata": {
        "id": "p32djmaXAqnU"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter = Multi30k(split='train',language_pair=(SRC_LANGUAGE,TGT_LANGUAGE))"
      ],
      "metadata": {
        "id": "QwLK6MqQBSfC"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_set = iter(train_iter)\n",
        "\n",
        "for n in range(5):\n",
        "  src,tgt = next(data_set)\n",
        "\n",
        "  print(f'sample: {str(n+1)}')\n",
        "  print(f'Source ({SRC_LANGUAGE}): {src}\\nTarget ({TGT_LANGUAGE}): {tgt}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Usu5HkdSCPRb",
        "outputId": "a3eb126a-87b7-45a2-d3e3-5ed6573d28c4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample: 1\n",
            "Source (de): Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.\n",
            "Target (en): Two young, White males are outside near many bushes.\n",
            "sample: 2\n",
            "Source (de): Mehrere Männer mit Schutzhelmen bedienen ein Antriebsradsystem.\n",
            "Target (en): Several men in hard hats are operating a giant pulley system.\n",
            "sample: 3\n",
            "Source (de): Ein kleines Mädchen klettert in ein Spielhaus aus Holz.\n",
            "Target (en): A little girl climbing into a wooden playhouse.\n",
            "sample: 4\n",
            "Source (de): Ein Mann in einem blauen Hemd steht auf einer Leiter und putzt ein Fenster.\n",
            "Target (en): A man in a blue shirt is standing on a ladder cleaning a window.\n",
            "sample: 5\n",
            "Source (de): Zwei Männer stehen am Herd und bereiten Essen zu.\n",
            "Target (en): Two men are at the stove preparing food.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "german,english = next(data_set)\n",
        "print(f\"Source German ({SRC_LANGUAGE}): {german}\\nTarget English  ({TGT_LANGUAGE}): { english }\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7GHPCNRGge3",
        "outputId": "947bea72-8096-4526-b1e1-e642758a03d6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source German (de): Ein Mann in grün hält eine Gitarre, während der andere Mann sein Hemd ansieht.\n",
            "Target English  (en): A man in green holds a guitar while the other man observes his shirt.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizers\n",
        "\n",
        "token_transform = {}\n",
        "\n",
        "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy',language='de_core_news_sm')\n",
        "token_transform[TGT_LANGUAGE] = get_tokenizer('spacy',language='en_core_web_sm')"
      ],
      "metadata": {
        "id": "PoU5Ik1LGqVi"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_transform['de'](german)\n",
        "token_transform['en'](english)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFgHEhUgHqVt",
        "outputId": "b3ac4597-c7f0-4387-86f3-3049caf05377"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A',\n",
              " 'man',\n",
              " 'in',\n",
              " 'green',\n",
              " 'holds',\n",
              " 'a',\n",
              " 'guitar',\n",
              " 'while',\n",
              " 'the',\n",
              " 'other',\n",
              " 'man',\n",
              " 'observes',\n",
              " 'his',\n",
              " 'shirt',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# special token indices\n",
        "\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0,1,2,3\n",
        "\n",
        "special_symbols = ['<unk>','<pad>','<bos>','<eos>']"
      ],
      "metadata": {
        "id": "1SV7-MfQH2lJ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_transform = {}\n",
        "\n",
        "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
        "  language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
        "\n",
        "  for data_sample in data_iter:\n",
        "    yield token_transform[language](data_sample[language_index[language]])"
      ],
      "metadata": {
        "id": "5HX7By9bJD5y"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vocab numericalizer\n",
        "\n",
        "for ln in [SRC_LANGUAGE,TGT_LANGUAGE]:\n",
        "  train_iterator = Multi30k(split='train',language_pair=(SRC_LANGUAGE,TGT_LANGUAGE))\n",
        "\n",
        "  sorted_dataset = sorted(train_iterator,key=lambda x: len(x[0].split()))\n",
        "\n",
        "  vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(sorted_dataset,ln),\n",
        "                                                  min_freq=1,\n",
        "                                                  specials=special_symbols,\n",
        "                                                  special_first=True)"
      ],
      "metadata": {
        "id": "WreiWmXlLbCG"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ln in [SRC_LANGUAGE,TGT_LANGUAGE]:\n",
        "  vocab_transform[ln].set_default_index(UNK_IDX)"
      ],
      "metadata": {
        "id": "IHjRL1qBNxCg"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_en = vocab_transform['en'](token_transform['en'](english))\n",
        "print(f'English text string: {english}\\nEnglish Sequence: {seq_en}')\n",
        "\n",
        "seq_de = vocab_transform['de'](token_transform['de'](german))\n",
        "print(f'German text string: {german}\\nGerman Sequence: {seq_de}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmoiIDJOOgl5",
        "outputId": "1cf2ea83-e5c5-4c39-bdaa-5cb79cda427a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English text string: A man in green holds a guitar while the other man observes his shirt.\n",
            "English Sequence: [6, 12, 7, 51, 144, 4, 126, 29, 8, 75, 12, 1748, 27, 23, 5]\n",
            "German text string: Ein Mann in grün hält eine Gitarre, während der andere Mann sein Hemd ansieht.\n",
            "German Sequence: [5, 12, 7, 657, 39, 18, 133, 8, 37, 16, 105, 12, 136, 41, 1779, 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "R_P9udVMP02Q"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add BOS token in front and EOS token at the end\n",
        "\n",
        "def tensor_transform_s(token_ids: List[int]):\n",
        "  return torch.cat((torch.tensor([BOS_IDX]),\n",
        "                    torch.flip(torch.tensor(token_ids),dims=(0,)),\n",
        "                    torch.tensor([EOS_IDX])))\n",
        "\n",
        "def tensor_transform_t(token_ids: List[int]):\n",
        "  return torch.cat((torch.tensor([BOS_IDX]),\n",
        "                    torch.tensor(token_ids),\n",
        "                    torch.tensor([EOS_IDX])))"
      ],
      "metadata": {
        "id": "3jK8YvYcP-mQ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_en1 = tensor_transform_t(seq_en)\n",
        "seq_en1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q63msxe-V8E8",
        "outputId": "8560a232-cc6b-4ff1-a4ee-a2df18f3e646"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([   2,    6,   12,    7,   51,  144,    4,  126,   29,    8,   75,   12,\n",
              "        1748,   27,   23,    5,    3])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_en2 = tensor_transform_s(seq_en)\n",
        "seq_en2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEB2HWp4WUhg",
        "outputId": "5cc86df7-156a-4065-f085-858bf8070c1f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([   2,    5,   23,   27, 1748,   12,   75,    8,   29,  126,    4,  144,\n",
              "          51,    7,   12,    6,    3])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# transform pipeline\n",
        "\n",
        "def sequential_transforms(*transforms):\n",
        "  def func(text_input):\n",
        "    for transform in transforms:\n",
        "      text_input = transform(text_input)\n",
        "    return text_input\n",
        "  return func\n",
        "\n",
        "text_transform = {}\n",
        "\n",
        "text_transform[SRC_LANGUAGE] = sequential_transforms(token_transform[SRC_LANGUAGE],\n",
        "                                                     vocab_transform[SRC_LANGUAGE],\n",
        "                                                     tensor_transform_s)\n",
        "\n",
        "text_transform[TGT_LANGUAGE] = sequential_transforms(token_transform[TGT_LANGUAGE],\n",
        "                                                     vocab_transform[TGT_LANGUAGE],\n",
        "                                                     tensor_transform_t)"
      ],
      "metadata": {
        "id": "pfGBojMoXn4Q"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# custom collate function\n",
        "\n",
        "def collate_fn(batch):\n",
        "  src_batch, tgt_batch = [], []\n",
        "  for src_sample,tgt_sample in batch:\n",
        "    src_sequences = text_transform[SRC_LANGUAGE](src_sample.rstrip('\\n'))\n",
        "    src_sequences = torch.tensor(src_sequences,dtype=torch.int64)\n",
        "    tgt_sequences = text_transform[TGT_LANGUAGE](tgt_sample.rstrip('\\n'))\n",
        "    tgt_sequences = torch.tensor(tgt_sequences,dtype=torch.int64)\n",
        "    src_batch.append(src_sequences)\n",
        "    tgt_batch.append(tgt_sequences)\n",
        "\n",
        "  src_batch = pad_sequence(src_batch,padding_value=PAD_IDX,batch_first=True)\n",
        "  tgt_batch = pad_sequence(tgt_batch,padding_value=PAD_IDX,batch_first=True)\n",
        "\n",
        "  return src_batch.to(device), tgt_batch.to(device)"
      ],
      "metadata": {
        "id": "BN2tvM2yai-N"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training and validation dataloaders\n",
        "\n",
        "BATCH_SIZE = 4\n",
        "\n",
        "train_iterator = Multi30k(split='train', language_pair=(SRC_LANGUAGE,TGT_LANGUAGE))\n",
        "sorted_train_iterator = sorted(train_iterator,key = lambda x: len(x[0].split()))\n",
        "train_dataloader = DataLoader(sorted_train_iterator,batch_size=BATCH_SIZE,collate_fn=collate_fn,drop_last=True)\n",
        "\n",
        "valid_iterator = Multi30k(split='valid',language_pair=(SRC_LANGUAGE,TGT_LANGUAGE))\n",
        "sorted_valid_dataloader = sorted(valid_iterator,key = lambda x: len(x[0].split()))\n",
        "valid_dataloader = DataLoader(sorted_valid_dataloader,batch_size=BATCH_SIZE,collate_fn=collate_fn,drop_last=True)\n",
        "\n",
        "src,trg = next(iter(train_dataloader))\n",
        "src,trg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BB0DQCMlcnHo",
        "outputId": "3e6ef2fc-4f1a-4b3c-a6fc-df4e818510c8"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[    2,     3,     1,     1,     1],\n",
              "         [    2,  5510,     3,     1,     1],\n",
              "         [    2,  5510,     3,     1,     1],\n",
              "         [    2,  1701,     8, 12642,     3]]),\n",
              " tensor([[   2,    3,    1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
              "         [   2, 6650, 4623,  259,  172, 9953,  115,  692, 3428,    5,    3],\n",
              "         [   2,  216,  110, 3913, 1650, 3823,   71, 2808, 2187,    5,    3],\n",
              "         [   2,    6, 3398,  202,  109,   37,    3,    1,    1,    1,    1]]))"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    }
  ]
}